{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# elec0135-assignment-cld\n\n## Workings Notebook\n\nI found it useful to work in Kaggle (given the 30 hours free per week of GPU time), then separate out the code into modules.\n\nI've kept this notebook in the repo to show a track record of commits and for my own future reference.\n\n### Kaggle Specific Code","metadata":{}},{"cell_type":"code","source":"# # Useful cleanups to reset status\n#!rm -rf /kaggle/working/data\n#!rm /kaggle/working/data.zip\n# !rm -rf /kaggle/working/artefacts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# also required in the `/interactive_runner.ipynb`\n!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-04-05T20:59:39.443173Z","iopub.execute_input":"2024-04-05T20:59:39.443747Z","iopub.status.idle":"2024-04-05T20:59:57.277389Z","shell.execute_reply.started":"2024-04-05T20:59:39.443698Z","shell.execute_reply":"2024-04-05T20:59:57.275796Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### `/model/util.py`","metadata":{}},{"cell_type":"code","source":"\"\"\"\nFunctions for creating and training models, used across the various tasks.\n\"\"\"\nimport dataclasses\nimport keras\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom tensorflow.data import Dataset\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, GlobalAveragePooling2D, MaxPooling2D\nfrom typing import NamedTuple, Tuple\n\n\n@dataclasses.dataclass\nclass Params():\n    \"\"\"\n    Job Parameters Struct\n    \"\"\"\n    image_size: int\n    batch_size: int\n    epochs: int\n    epsilon: float\n    early_stopping: bool\n    early_stopping_patience: int\n    adjust_learning_rate: bool\n    opt: type\n        \n        \nclass ResultCollector():\n    \"\"\"\n    Utility class to collect up and output results from tasks.\n    \"\"\"\n    \n    TRAIN_DETAILS_FILE = \"train_details.csv\"\n    TEST_SCORES_FILE = \"test_scores.csv\"\n    \n    def __init__(\n        self,\n        path: Path\n    ):\n        self.path = path\n        self.train_details = pd.DataFrame\n        self.test_scores = pd.DataFrame\n        \n    def get_path(self) -> Path:\n        \"\"\" Returns the path to which the collectors stores results \"\"\"\n        return self.path\n\n    def add_task_results(self, df_train, df_test) -> None:\n        \"\"\" Add training details and test scores into the collector\"\"\"\n        self._add_train_details(df_train)\n        self._add_test_scores(df_test)\n        \n    def get_train_details(self) -> pd.DataFrame:\n        \"\"\" Returns the training details collected \"\"\"\n        return self.train_details\n               \n    def get_test_scores(self) -> pd.DataFrame:\n        \"\"\" Returns the test scores collected \"\"\"\n        return self.test_scores\n    \n    def restore_results(self, quietly = True) -> None:\n        \"\"\" Loads results from the location of get_path()\"\"\"\n        try:\n            self.train_details = pd.read_csv(self.path / self.TRAIN_DETAILS_FILE)\n            self.test_scores = pd.read_csv(self.path / self.TEST_SCORES_FILE)\n        except FileNotFoundError:\n            print(\"Unable to restore history - starting fresh\")\n            if not quietly:\n                raise\n\n    def _add_train_details(self, df: pd.DataFrame) -> None:\n        if self.train_details.empty:\n            self.train_details = df\n        else:\n            self.train_details = pd.concat([self.train_details, df])\n        \n        self._save(self.train_details, self.TRAIN_DETAILS_FILE)        \n        \n    def _add_test_scores(self, df: pd.DataFrame) -> None:\n        if self.test_scores.empty:\n            self.test_scores = df\n        else:\n            self.test_scores = pd.concat([self.test_scores, df])\n            \n        self._save(self.test_scores, self.TEST_SCORES_FILE)\n                \n    def _save(self, df: pd.DataFrame, name: str) -> None:\n        df.to_csv(self.path / name, index=False)\n\n\n@dataclasses.dataclass\nclass ModelWrapper():\n    \"\"\"\n    Utility class to hold the \"outer\" model, and the inner base model\n    so that training can be fine-tuned if required.\n    \"\"\"    \n    model: keras.Model\n    base_model: keras.Model\n\n\ndef create_model(base_model_fn: str, params: Params, fc_layers = 2, fc_neurons = 1024, batch_norm = False) -> ModelWrapper:\n    \"\"\"\n    Create Keras application model, e.g.\n        tf.keras.applications.EfficientNetV2B0\n        tf.keras.applications.ConvNeXtBase\n    with a custom top.\n    \"\"\"\n    inputs = keras.Input(shape=(params.image_size, params.image_size, 3))\n    # Base\n    base_model = base_model_fn(weights='imagenet', include_top=False)\n    base_model.trainable = False\n    # set training=F here per https://keras.io/guides/transfer_learning/\n    x = base_model(inputs, training=False)\n    # Head\n    x = GlobalAveragePooling2D()(x)\n    if batch_norm:\n        x = BatchNormalization()(x)\n    x = Flatten()(x)\n    \n    l = 0\n    while (l < fc_layers):\n        x = Dense(fc_neurons, activation=\"relu\")(x)\n        x = Dropout(0.5)(x)\n        l = l + 1\n    \n    outputs = Dense(5, activation=\"softmax\")(x)\n    model = keras.Model(inputs, outputs)\n\n    return ModelWrapper(model, base_model)\n\n\ndef run_task(task_id: str, model_wrapper: ModelWrapper,\n             ds_train: Dataset, ds_valid: Dataset, ds_test: Dataset,\n             params: Params, collector: ResultCollector, weights = None) -> None:\n    \"\"\"\n    Main task running function.\n    \"\"\"\n    print(f\"Running Task: {task_id} with params {params}\")\n    return\n    model = model_wrapper.model\n    # train\n    start = datetime.datetime.now()\n    df_train = _train(task_id, model, ds_train, ds_valid, params)\n    end = datetime.datetime.now()\n    # test\n    test_result = model.evaluate(ds_test)\n    df_test = _create_test_record(task_id, test_result, (end-start))\n    # save CM too\n    _save_confusion_matrix(collector.get_path(), ds_test, model, task_id)\n\n\ndef _train(task_id: str, model: Model,\n             ds_train_: Dataset, ds_valid_: Dataset,\n             params: Params, weights = None) -> pd.DataFrame:\n    \n    opt = params.opt\n    print(f\"Using: {opt}\")\n\n    model.compile(\n        optimizer=params.opt(epsilon=params.epsilon),\n        loss=\"categorical_crossentropy\",\n        metrics=['accuracy']\n    )\n\n    early_stopping = callbacks.EarlyStopping(\n        min_delta=0.0001,\n        patience=params.early_stopping_patience,\n        restore_best_weights=True,\n        verbose = 1\n    )\n    \n    reduce_lr = callbacks.ReduceLROnPlateau(\n        monitor = 'val_loss', factor = 0.3, \n        patience = 3, min_delta = 0.0005, \n        mode = 'min', verbose = 1)\n    \n    cbs = []\n    if params.early_stopping:\n        print(\"Using EarlyStopping\")\n        cbs += [early_stopping]\n    if params.adjust_learning_rate:\n        print(\"Using ReduceLROnPlateau\")\n        cbs += [reduce_lr]\n\n    assert 1==2, \"break\"\n\n    history = model.fit(\n        ds_train_,\n        validation_data=ds_valid_,\n        epochs=params.epochs,\n        verbose=1,\n        callbacks=cbs,\n        class_weight=weights\n    )\n   \n    df_hist = pd.DataFrame(history.history)\n    df_hist[\"task_id\"] = task_id\n    df_hist[\"epoch\"] = df_hist.index\n   \n    return df_hist\n\n\ndef _create_test_record(task_id: str, result: list[float], duration: timedelta):\n    return pd.DataFrame({\"task_id\": [task_id], \"test_loss\" : [result[0]], \"time_secs\": [duration.seconds]})\n\n\ndef _save_confusion_matrix(path: Path, ds: Dataset, model: Model, task_id: str) -> None:\n    filepath = f\"artefacts/conf_mat_{task_id}.png\"\n    filepath = path / filepath\n    \n    probabilities = model.predict(ds)\n    predictions = np.argmax(probabilities, axis=1)\n\n    one_hot_labels = np.concatenate([y for x, y in ds], axis=0)\n    labels = [np.argmax(x) for x in one_hot_labels]\n    \n    result = confusion_matrix(labels, predictions, labels=[0,1,2,3,4], normalize='pred')\n    disp = ConfusionMatrixDisplay(result, display_labels=[0,1,2,3,4])\n    disp.plot()\n    disp.ax_.set_title(task_id)\n    \n    print(f\"Saving confusion matrix to {path}\")\n    disp.figure_.savefig(filepath, dpi=300)\n    \n    \ndef create_vgg_like_model(params: Params) -> ModelWrapper:\n    inputs = keras.Input(shape=(params.image_size, params.image_size, 3))\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Dropout(0.25)(x)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Dropout(0.25)(x)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Dropout(0.25)(x)\n\n    # classification layers\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n\n    outputs = Dense(5, activation=\"softmax\")(x)\n    model = keras.Model(inputs, outputs)\n\n    return ModelWrapper(model, None)\n\n\n\ndef create_simple_model(params: Params) -> Model:\n    m = keras.Sequential([\n        \n        tf.keras.Input(shape=(params.image_size, params.image_size, 3)),\n        \n        # First Convolutional Block\n        layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same'),\n        layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.MaxPool2D(),\n        layers.Dropout(0.2),\n\n        # Second Convolutional Block\n        layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.MaxPool2D(),\n        layers.Dropout(0.2),\n\n        # Third Convolutional Block\n        layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.MaxPool2D(),\n        layers.Dropout(0.2),\n\n        # Classifier Head\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.Dense(units=5, activation=\"softmax\"),\n    ])\n    return ModelWrapper(m, None)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:07:12.792616Z","iopub.execute_input":"2024-04-05T21:07:12.793073Z","iopub.status.idle":"2024-04-05T21:07:12.853182Z","shell.execute_reply.started":"2024-04-05T21:07:12.793040Z","shell.execute_reply":"2024-04-05T21:07:12.851772Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### `/data/data_processing.py`","metadata":{}},{"cell_type":"code","source":"import gdown\nimport keras\nimport pandas as pd\nimport random\nimport shutil\nimport tensorflow as tf\nimport os\nimport zipfile\n\n# handle different structure Kaggle (Notebook) vs. Colab (Modules)\n# this wouldn't be kept in any \"production\" version.\ntry:\n    from AMLS_II_assignment23_24.model.util import Params\nexcept ModuleNotFoundError:\n    pass\n\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.data import Dataset\nfrom tensorflow.data.experimental import AUTOTUNE\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom typing import Tuple\n\n\ndef data_preprocessing(path: Path, params: Params, force=False) -> Tuple[Dataset, Dataset, Dataset, dict]:\n    \"\"\"\n    Main data preprocessing function - extracts the data to the given path.\n    Returns a tuple of Training, Validation, Test datasets, along with class weights.\n    \"\"\"\n    file = _download_data(path, force)\n    \n    data_path = path / \"data\"\n    if force:\n        shutil.rmtree(data_path)\n        \n    if not data_path.exists():\n        data_path.mkdir(parents=True, exist_ok=True)\n       \n        with zipfile.ZipFile(file, \"r\") as z:\n            z.extractall(data_path)\n        \n    df_images = pd.read_csv((data_path / \"train.csv\"))\n       \n    X_train, X_test, y_train, y_test = train_test_split(df_images.image_id, df_images.label, test_size=0.2, random_state=12)\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=12)\n    \n    train_path = _create_ds_tree(X_train, y_train, data_path, \"train\")\n    valid_path = _create_ds_tree(X_valid, y_valid, data_path, \"valid\")\n    test_path = _create_ds_tree(X_test, y_test, data_path, \"test\")\n    \n    ds_train = _create_dataset(train_path, params.image_size, params.batch_size)\n    ds_valid = _create_dataset(valid_path, params.image_size, params.batch_size)\n    ds_test = _create_dataset(test_path, params.image_size, params.batch_size, False)\n\n    return ds_train, ds_valid, ds_test, _extract_class_weights(df_images)\n\n\ndef _download_data(path: Path, force=False) -> Path:\n    \"\"\"\n    Downloads the data from the author's Google Drive account.\n    \"\"\"\n    url = \"https://drive.google.com/uc?id=1TJBf1HZxAMpowZ92BcgS5N_NPHE7LPOT\"\n    output = path / \"data.zip\"\n    if not Path(output).exists() or force:\n        gdown.download(url, str(output), quiet=False)\n    return output\n\n\ndef _create_ds_tree(x, y, path: Path, name: str) -> Path:\n    \"\"\"\n    Creates the directory structure for the given dataset.\n    \"\"\"\n    ds_path = path / name\n    if not ds_path.exists():\n        ds_path.mkdir(parents=True, exist_ok=True)\n\n        for lab in y.unique():\n            (ds_path / str(lab)).mkdir(exist_ok=True)\n\n        source_path = path / \"train_images\"\n        \n        for img, lab in zip(x, y):\n            src = source_path / img\n            dest = ds_path / str(lab) / img\n            shutil.move(src, dest)\n        \n    return ds_path\n\n\ndef _create_dataset(path: Path, img_size: int, batch_size: int, shuffle = True) -> Dataset:\n    \"\"\"\n    Builds up the Dataset object from the given path.\n    \"\"\"\n    return image_dataset_from_directory(\n        path,\n        labels='inferred',\n        label_mode='categorical',\n        image_size=[img_size, img_size],\n        batch_size=batch_size,\n        seed=12345,\n        shuffle=shuffle,\n        crop_to_aspect_ratio=True\n    )\n\n\ndef _extract_class_weights(df_data: pd.DataFrame) -> dict:\n    \"\"\"\n    Uses the descriptive DataFrame to calculate the class weights\n    from the distribution of the labels.\n    \"\"\"\n    classes = df_data.label.unique()\n    class_weights = compute_class_weight(class_weight='balanced',\n                                         classes=classes,\n                                         y=df_data.label)\n\n    return dict(zip(classes, class_weights))\n\n\ndef convert_dataset_to_float(ds: Dataset) -> Dataset:\n    \"\"\"\n    Some models require the input to be coverted to float tensors and\n    normalised into a 0-1 range.\n    \"\"\"\n    def convert_to_float(image, label):\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        image = image / 255.0\n        return image, label\n\n    return ds.map(convert_to_float)\n    \n\ndef cache_dataset(ds: Dataset) -> Dataset:\n    \"\"\"\n    Dataset caching/pre-fetch utility.\n    \"\"\"\n    return (\n        ds\n        .cache()\n        .prefetch(buffer_size=AUTOTUNE)\n    )\n\n\ndef augment_dataset(ds: Dataset, num_repeats: int = 1) -> Dataset:\n    \"\"\"\n    Augment the given dataset by flipping left/right, up/down, and\n    adjusting the brightness.\n    \"\"\"\n    def augment(image, label):\n        seed = 12345\n        image = tf.image.random_flip_left_right(image, seed)\n        image = tf.image.random_flip_up_down(image, seed)\n        image = tf.image.random_brightness(image, 0.2, seed)\n        return image, label\n\n    return (\n        ds\n        .repeat(num_repeats)\n        .map(augment)\n    )\n\ndef over_sample_class(ds: Dataset, class_label: int, batch_size: int, num_repeats: int = 1) -> Dataset:\n    \"\"\"\n    Over-samples the given class label by the number of repeats given.  Re-batch to the given size.\n    Returns a combined, reshuffled dataset.\n    \"\"\"\n    # filter dataset to just the class_label\n    ds_filt = ds.unbatch().filter(lambda x, label: tf.equal(tf.argmax(label, axis=0), class_label))\n    ds_filt = ds.repeat(num_repeats)\n    # combined with original dataset, re-shuffle, and re-batch\n    ds_over = tf.data.Dataset.concatenate(ds.unbatch(), ds_filt)\n    ds_over = ds_over.shuffle(100000)\n    ds_over = ds_over.batch(batch_size)\n    return ds_over\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:07:13.189726Z","iopub.execute_input":"2024-04-05T21:07:13.190918Z","iopub.status.idle":"2024-04-05T21:07:13.228000Z","shell.execute_reply.started":"2024-04-05T21:07:13.190843Z","shell.execute_reply":"2024-04-05T21:07:13.226516Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### `/report.py`?","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:37:47.062863Z","iopub.execute_input":"2024-04-05T10:37:47.063224Z","iopub.status.idle":"2024-04-05T10:37:47.067978Z","shell.execute_reply.started":"2024-04-05T10:37:47.063198Z","shell.execute_reply":"2024-04-05T10:37:47.066722Z"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_task_comp(df_history: pd.DataFrame, task_ids: list, epoch_limit = 50) -> None:\n    df = df_history[(df_history.task_id.isin(task_ids)) & (df_history.epoch <= epoch_limit)].copy()\n    df[\"loss_gap\"] = df.val_loss - df.loss\n    df_grp = df[[\"epoch\",\"task_id\", \"val_accuracy\", \"val_loss\", \"loss_gap\"]].groupby([\"epoch\", \"task_id\"]).mean()\n    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(16, 8))\n    sns.lineplot(data=df_grp, x=\"epoch\", y=\"val_accuracy\", hue=\"task_id\",  ax=ax1)\n    sns.lineplot(data=df_grp, x=\"epoch\", y=\"val_loss\", hue=\"task_id\",  ax=ax2)\n    sns.lineplot(data=df_grp, x=\"epoch\", y=\"loss_gap\", hue=\"task_id\",  ax=ax3)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:07:13.465987Z","iopub.execute_input":"2024-04-05T21:07:13.466870Z","iopub.status.idle":"2024-04-05T21:07:13.478336Z","shell.execute_reply.started":"2024-04-05T21:07:13.466827Z","shell.execute_reply":"2024-04-05T21:07:13.476418Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### `/main.py`","metadata":{}},{"cell_type":"code","source":"import datetime\nimport os\nimport pandas as pd\nimport tensorflow as tf\n\n# handle different structure Kaggle (Notebook) vs. Colab (Modules)\n# this wouldn't be kept in any \"production\" version.\ntry:\n    from AMLS_II_assignment23_24.data_processing.pre_processing import data_preprocessing, rebatch\n    from AMLS_II_assignment23_24.model import util as model_util\n    from AMLS_II_assignment23_24.model.util import Params, ResultCollector, create_model\nexcept ModuleNotFoundError:\n    pass\n\nfrom docopt import docopt\nfrom pathlib import Path\nfrom tensorflow.keras.optimizers import Adam, AdamW\n\ntf.random.set_seed(67890)\n\n# Starting set of params\nparams = Params(255, 196, 50, 0.005, True, 7, False, Adam)\n\nARTEFACTS_PATH = Path(\"artefacts\")\nARTEFACTS_PATH.mkdir(parents=True, exist_ok=True)\n\ncollector = ResultCollector(ARTEFACTS_PATH)\ncollector.restore_results()\n\n# Process Data\nprint(\"================\")\nprint(\"= Loading Data =\")\nprint(\"================\")\ncwd = os.getcwd()\nds_train, ds_valid, ds_test, class_weights = data_preprocessing(Path(cwd), params)\nprint(f\"Class Weights: {class_weights}\")\n\nprint(\"\\n==== Task A: Explore Batch Size ====\")\nfor bs in [64, 128, 192, 256]:\n    print(f\"Batch Size: {bs}\")\n    ds_train = ds_train.rebatch(bs)\n    ds_valid = ds_valid.rebatch(bs)\n    model = create_model(tf.keras.applications.ConvNeXtTiny, params)\n    run_task(f\"A_{bs}\", model, ds_train, ds_valid, ds_test, params, collector)\n\n# update based on results of Task A\nparams.batch_size = 256\nds_train, ds_valid, ds_test, class_weights = data_preprocessing(Path(cwd), params)\n\nprint(\"\\n==== Task B: Explore Epsilon ====\")\nfor e in [0.0025, 0.0050, 0.0075, 0.01]:\n    print(f\"Epsilon: {e}\")\n    p = dataclasses.replace(params)\n    p.epsilon = e\n    model = create_model(tf.keras.applications.ConvNeXtTiny, p)\n    run_task(f\"B_{e}\", model, ds_train, ds_valid, ds_test, p, collector)\n\n# update based on results of Task B\nparams.epsilon = 0.0075\n\nprint(\"\\n==== Task C: Baseline Model Comparison ====\")\nfor m in [tf.keras.applications.ConvNeXtTiny, tf.keras.applications.ConvNeXtBase,\n          tf.keras.applications.EfficientNetB0, tf.keras.applications.EfficientNetV2B0]:\n    print(f\"Model: {m}\")\n    model = create_model(m, params)\n    run_task(f\"C_{model.base_model.name}\", model, ds_train, ds_valid, ds_test, params, collector)\n\nprint(\"\\n==== Task D: Best-of-Breed Model ====\")\n# oversample & augment dataset\nds_train_aug = augment_dataset(over_sample_class(ds_train, 0, params.batch_size), 2)\n# initial training\nmodel_d = create_model(tf.keras.applications.EfficientNetV2B0, params, bn=True)\nrun_task(f\"D_base\", model_d, ds_train, ds_valid, ds_test, params, collector, class_weights)\n# fine-tune by allowing base model to be re-trained\nmodel_d.base_model.trainable = True\nft_params = dataclasses.replace(params)\nft_params.epsilon = 1e-5\nrun_task(f\"D_tuned\", model, ds_train_aug, ds_valid, ds_test, ft_params, collector, class_weights)\ndel model_d\n\nprint(\"\\n========================\")\nprint(\"==== Ablation Study ====\")\nprint(\"========================\")\n\nprint(\"\\n==== Task E: Remove Fine-Tuning ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params, bn=True)\nrun_task(f\"E\", model, ds_train_aug, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task F: Remove Class Weights ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params, bn=True)\nrun_task(f\"F\", model, ds_train_aug, ds_valid, ds_test, params, collector)\ndel model\n\nprint(\"\\n==== Task G: Remove Data Augmentation ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params, bn=True)\nrun_task(f\"G\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task H: Remove Batch Norm ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params)\nrun_task(f\"H\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task I: Regress to the Adam Optimiser ====\")\nparams.opt = Adam\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params)\nrun_task(f\"I\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task J: Remove a FC Layer ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params, 1)\nrun_task(f\"J_1\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task J: Add a FC Layer ====\")\nmodel = create_model(tf.keras.applications.ConvNeXtBase, params, 3)\nrun_task(f\"J_3\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model\n\nprint(\"\\n==== Task K: Create a Custom Convnet ====\")\nmodel = create_simple_model(params)\nrun_task(f\"K\", model, ds_train, ds_valid, ds_test, params, collector, class_weights)\ndel model","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:14:30.300231Z","iopub.execute_input":"2024-04-05T21:14:30.301967Z","iopub.status.idle":"2024-04-05T21:15:28.176484Z","shell.execute_reply.started":"2024-04-05T21:14:30.301880Z","shell.execute_reply":"2024-04-05T21:15:28.174904Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"================\n= Loading Data =\n================\nFound 6489 files belonging to 5 classes.\nFound 2163 files belonging to 5 classes.\nFound 2164 files belonging to 5 classes.\nClass Weights: {0: 1.990064397424103, 3: 0.8394256887854094, 1: 0.9882137962539973, 2: 0.9066219614417435, 4: 0.8394256887854094}\n\n\n==== Task A: Explore Batch Size ====\nBatch Size: 64\nRunning Task: A_64 with params Params(image_size=255, batch_size=196, epochs=50, epsilon=0.005, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nBatch Size: 128\nRunning Task: A_128 with params Params(image_size=255, batch_size=196, epochs=50, epsilon=0.005, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nBatch Size: 192\nRunning Task: A_192 with params Params(image_size=255, batch_size=196, epochs=50, epsilon=0.005, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nBatch Size: 256\nRunning Task: A_256 with params Params(image_size=255, batch_size=196, epochs=50, epsilon=0.005, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nFound 6489 files belonging to 5 classes.\nFound 2163 files belonging to 5 classes.\nFound 2164 files belonging to 5 classes.\n\n\n==== Task B: Explore Epsilon ====\nEpsilon: 0.0025\nRunning Task: B_0.0025 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0025, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nEpsilon: 0.005\nRunning Task: B_0.005 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.005, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nEpsilon: 0.0075\nRunning Task: B_0.0075 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nEpsilon: 0.01\nRunning Task: B_0.01 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.01, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n==== Task C: Baseline Model Comparison ====\nModel: <function ConvNeXtTiny at 0x78a86dfc1a20>\nRunning Task: C_convnext_tiny with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nModel: <function ConvNeXtBase at 0x78a86dfc1b40>\nRunning Task: C_convnext_base with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nModel: <function EfficientNetB0 at 0x78a86dfc27a0>\nRunning Task: C_efficientnetb0 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nModel: <function EfficientNetV2B0 at 0x78a86dfc32e0>\nRunning Task: C_efficientnetv2-b0 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n\n==== Task D: Best-of-Breed Model ====\nRunning Task: D_base with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\nRunning Task: D_tuned with params Params(image_size=255, batch_size=256, epochs=50, epsilon=1e-05, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n\n========================\n==== Ablation Study ====\n========================\n\n==== Task E: Remove Fine-Tuning ====\nRunning Task: E with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task F: Remove Class Weights ====\nRunning Task: F with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task G: Remove Data Augmentation ====\nRunning Task: G with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task H: Remove Batch Norm ====\nRunning Task: H with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task I: Regress to the Adam Optimiser ====\nRunning Task: I with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task J: Remove a FC Layer ====\nRunning Task: J_1 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task J: Add a FC Layer ====\nRunning Task: J_3 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n\n==== Task K: Create a Custom Convnet ====\nRunning Task: J_3 with params Params(image_size=255, batch_size=256, epochs=50, epsilon=0.0075, early_stopping=True, early_stopping_patience=7, adjust_learning_rate=False, opt=<class 'keras.src.optimizers.adam.Adam'>)\n","output_type":"stream"}]},{"cell_type":"code","source":"m1 = create_model(tf.keras.applications.ConvNeXtTiny, params, 2, 1024)\nm1.model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T21:16:31.191151Z","iopub.execute_input":"2024-04-05T21:16:31.191626Z","iopub.status.idle":"2024-04-05T21:16:32.935415Z","shell.execute_reply.started":"2024-04-05T21:16:31.191595Z","shell.execute_reply":"2024-04-05T21:16:32.934183Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_651\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_651\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_646 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ convnext_tiny (\u001b[38;5;33mFunctional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │    \u001b[38;5;34m27,820,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_119    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_123 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_369 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m787,456\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_258 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_370 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_259 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_371 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_646 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ convnext_tiny (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_119    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_369 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_258 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_370 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_259 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_371 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,662,309\u001b[0m (113.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,662,309</span> (113.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,842,181\u001b[0m (7.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,842,181</span> (7.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m27,820,128\u001b[0m (106.13 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,820,128</span> (106.13 MB)\n</pre>\n"},"metadata":{}}]}]}